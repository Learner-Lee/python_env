# Streamlit ç¯å¢ƒæ­å»ºä¸éªŒè¯

## pycharmå®‰è£…

ç½‘å€ï¼šhttps://www.jetbrains.com/pycharm/
![image-20250626125741718](assets/image-20250626125741718.png)



## åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

### 1.åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹ä½¿ç”¨ CMD æ‰“å¼€ç»ˆç«¯

![image-20250626130007118](assets/image-20250626130007118.png)



### 2.åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```ini
python3.9 -m venv myenv
```

![image-20250626130315170](assets/image-20250626130315170.png)

#### æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```ini
cd C:\Users\Death master\Desktop\work\code\Streamlit\code\myenv\Scripts

activate
```

![image-20250626130847962](assets/image-20250626130847962.png)

![image-20250626130656584](assets/image-20250626130656584.png)

#### é€€å‡ºè™šæ‹Ÿç¯å¢ƒ

```ini
deactivate
```

![image-20250626130724403](assets/image-20250626130724403.png)







### 3.Streamlit å®‰è£…

#### ç¡®è®¤ Python å’Œ pip å®‰è£…

```ini
python3.9 --version
pip3.9 --version
```

![image-20250626131155712](assets/image-20250626131155712.png)



#### å®‰è£… Streamlit 

```
pip3.9 install streamlit
```

![image-20250626131300616](assets/image-20250626131300616.png)



#### Streamlit ç¯å¢ƒæ­å»º

##### åˆ›å»ºrequirements.txt

![image-20250626134836830](assets/image-20250626134836830.png)

##### è¿è¡Œ

```ini
pip install -r requirements.txt
```

![image-20250626134516965](assets/image-20250626134516965.png)





#### Streamlit éªŒè¯

```ini
streamlit hello
```

![image-20250626135330595](assets/image-20250626135330595.png)

![image-20250626135304686](assets/image-20250626135304686.png)



##### ç¬¬ä¸€ä¸ªç¨‹åº

```python
import streamlit as st

st.write('My first line text')

st.write("""
# My first app
Hello *world!*I
""")
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626135755564](assets/image-20250626135755564.png)









# Streamlit Concepts

### åˆ›å»ºè¡¨æ ¼

```python
import pandas as pd

st.write("Here's our first attempt at using data tocreateatable")
st.write(pd.DataFrame({
    'first column': [1, 2, 3, 4], 'second column': [10, 20, 30, 40]
}))
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626151112230](assets/image-20250626151112230.png)







### æ˜¾ç¤ºåŠ¨æ€è¡¨æ ¼

```python
import numpy as np

dataframe = pd.DataFrame(
    np.random.randn(10, 20), columns=[f'column_{i}' for i in range(20)]
)
st.dataframe(dataframe.style.highlight_max(axis=0))
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626151318592](assets/image-20250626151318592.png)





### æ˜¾ç¤ºå›¾è¡¨å’Œåœ°å›¾

#### st.line_chart

```python
import numpy as np

chart_data = pd.DataFrame(
    np.random.randn(20, 3), columns=['a', 'b', 'c']
)
st.line_chart(chart_data)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626151607981](assets/image-20250626151607981.png)





#### st.map

```python
map_data = pd.DataFrame(
    np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4], columns=['lat', 'lon']
)
st.map(map_data)
```

> å…³é”®è¯´æ˜ï¼š
>
> â€¢ è¾“å…¥æ•°æ®éœ€åŒ…å«latï¼ˆçº¬åº¦ï¼‰å’Œlonï¼ˆç»åº¦ï¼‰åˆ—ï¼› 
>
> â€¢ è‡ªåŠ¨èšåˆå¯†é›†ç‚¹ï¼Œæ”¯æŒåœ°å›¾ç¼©æ”¾å’Œå¹³ç§»ã€‚

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626152001003](assets/image-20250626152001003.png)



### æ˜¾ç¤ºWidgets

Streamlit äº¤äº’ç»„ä»¶ï¼ˆWidgetsï¼‰æ ¸å¿ƒèƒ½åŠ› 

â€¢ Widgets æ˜¯ Streamlit å®ç°ç”¨æˆ·äº¤äº’çš„å…³é”®ç»„ä»¶ï¼Œæ”¯æŒæ»‘å—ã€è¾“å…¥æ¡†ã€ä¸‹æ‹‰æ¡†ç­‰å¤šç§å½¢å¼ï¼Œæ— éœ€å¤æ‚äº‹ä»¶ç›‘å¬å³å¯å®ç°æ•°æ®åŒå‘ç»‘å®šã€‚ 

ä¸‰å¤§åº”ç”¨åœºæ™¯ï¼šå‚æ•°è°ƒèŠ‚ã€æ•°æ®è¾“å…¥ã€é€‰é¡¹é€‰æ‹©ã€‚



#### è°ƒèŠ‚æ»‘å— â€”â€”st.slider

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ ä¸‰ä¸ªå‚æ•°ï¼šæ ‡ç­¾ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€é»˜è®¤å€¼ï¼› 
>
> â€¢ è‡ªåŠ¨ç»‘å®šå˜é‡xï¼Œå€¼éšæ»‘å—ç§»åŠ¨å®æ—¶æ›´æ–°ã€‚

```python
x = st.slider('x', 0, 100, 50)
st.write(x, 'squared is', x * x)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626152702010](assets/image-20250626152702010.png)





#### æ–‡æœ¬è¾“å…¥ â€”â€”st.text_input

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ key="name"ç”¨äºå­˜å‚¨è¾“å…¥å€¼åˆ°st.session_stateï¼› 
>
> â€¢ æ”¯æŒå®æ—¶è¾“å…¥åé¦ˆï¼Œæ— éœ€æ‰‹åŠ¨æäº¤æŒ‰é’®ã€‚

```python
user_name = st.text_input("Your name", key="name")
st.write("Hello,", user_name)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626152941205](assets/image-20250626152941205.png)





#### é€‰æ‹©ä¸‹æ‹‰æ¡† â€”â€”st.selectbox

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ æ•°æ®ç»‘å®šï¼šæ‰€æœ‰ Widgets é€šè¿‡keyå‚æ•°ç»‘å®šåˆ°st.session_stateï¼Œå®ç°çŠ¶æ€æŒä¹…åŒ–ï¼›
>
> â€¢ è”åŠ¨æ•ˆæœï¼šå¤šä¸ª Widgets å¯è”åŠ¨æ§åˆ¶åŒä¸€å›¾è¡¨ï¼ˆå¦‚æ»‘å—è°ƒèŠ‚å›¾è¡¨èŒƒå›´+ä¸‹æ‹‰æ¡†é€‰æ‹©æ•°æ®åˆ—ï¼‰ï¼›
>
> â€¢ æ€§èƒ½ä¼˜åŒ–ï¼šé¿å…åœ¨å¾ªç¯ä¸­åˆ›å»º Widgetsï¼Œé˜²æ­¢é‡å¤æ¸²æŸ“ã€‚

```python
df = pd.DataFrame({
    'first column': [1, 2, 3, 4], 'second column': [10, 20, 30, 40]
})
option = st.selectbox(
    'Which number do you like best?', df['first column']
)
st.write('You selected:', option)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250626153122092](assets/image-20250626153122092.png)







#### ä¾§è¾¹æ é…ç½®åŒº â€”â€”st.sidebar

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ é€šè¿‡with st.sidebar:è¿›å…¥ä¾§è¾¹æ ä¸Šä¸‹æ–‡ï¼› 
>
> â€¢ ä¾§è¾¹æ ç»„ä»¶æ”¯æŒæ‰€æœ‰ Widgetsï¼ˆä¸‹æ‹‰æ¡†ã€æ»‘å—ã€æ–‡æœ¬è¾“å…¥ç­‰ï¼‰ã€‚

```python
with st.sidebar:
    st.header("Image/Video Config")
    source = st.selectbox(
        "Choose a source",
        ["Image", "Video"]
    )
    confidence = st.slider(
        "Confidence", 0.0, 1.0, 0.5
    )
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627002632352](assets/image-20250627002632352.png)







#### ä¾§è¾¹æ å¤šç»„ä»¶ç»„åˆ

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ ä¾§è¾¹æ æ”¯æŒä»»æ„ç»„ä»¶ç»„åˆï¼Œå½¢æˆå®Œæ•´é…ç½®é¢æ¿ï¼› 
>
> â€¢ å®æ—¶åé¦ˆç”¨æˆ·é€‰æ‹©ï¼Œæå‡äº¤äº’ä½“éªŒã€‚

```python
with st.sidebar:
    st.title("YOLOv8 Config")
    model_size = st.radio(
        "Model Size",
        ["nano", "small", "medium"]
    )
    use_gpu = st.checkbox("Use GPU Acceleration")
    st.write(f"Selected: {model_size}, GPU: {use_gpu}")
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627002902358](assets/image-20250627002902358.png)







#### ä¸»ç•Œé¢åˆ†æ  â€”â€”st.columns

> å…³é”®è¯´æ˜ï¼š 
>
> â€¢ st.columns(2)åˆ›å»ºä¸¤åˆ—ï¼Œè¿”å›åˆ—å¯¹è±¡åˆ—è¡¨ï¼› 
>
> â€¢ é€šè¿‡with col:è¿›å…¥åˆ—ä¸Šä¸‹æ–‡ï¼Œå†…éƒ¨ç»„ä»¶ä»…åœ¨è¯¥åˆ—æ˜¾ç¤ºã€‚

```python
col1, col2 = st.columns(2)
with col1:
    st.header("Original Image")
	st.image("input.jpg")
with col2:
    st.header("Detected Image")
	st.image("output.jpg")
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627011905967](assets/image-20250627011905967.png)







#### åˆ—å¸ƒå±€ä¸­çš„ç»„ä»¶äº¤äº’

```python
left, right = st.columns([1, 2])
with left:
    st.button("Generate Random Data")
with right:
    data = np.random.randn(10, 5)
    st.dataframe(data)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627012001802](assets/image-20250627012001802.png)





#### ä¾§è¾¹æ ä¸‹æ‹‰æ¡†

```python
# ä¾§è¾¹æ ä¸‹æ‹‰æ¡†
add_selectbox = st.sidebar.selectbox(
    'How would you like to be contacted?', ('Email', 'Home phone', 'Mobile phone')
)
# ä¾§è¾¹æ èŒƒå›´æ¡†
add_slider = st.sidebar.slider(
    'Select a range of values', 0.0, 100.0, (25.0, 75.0)
)
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627012324500](assets/image-20250627012324500.png)







#### å•é€‰æ¡†

```python
left_column, right_column = st.columns(2)
left_column.button('Press me!')
with right_column:
    dog_breed = st.radio(
        'Choose Dog Breed:', options=['Husky', 'Corgi', 'Chihuahua', 'Spotty'], index=0
    )
    st.write(f"You selected: {dog_breed}")
```

åœ¨å‘½ä»¤è¡Œè¿è¡Œ

```ini
streamlit run app.py
```

![image-20250627012441227](assets/image-20250627012441227.png)













# YOLOV8å›¾åƒç›®æ ‡æ£€æµ‹

â€¢ åœ¨requirements.txtä¸­æ·»åŠ åŒ…. 

```
ultralytics 
```

â€¢ PyCharmç»ˆç«¯ï¼Œé€šè¿‡å¦‚ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£… 

```
pip install -r requirements.txt
```





## è®¾ç½®è·¯å¾„

åœ¨main.pyä¸­ï¼Œå£°æ˜å˜é‡è®¾ç½®yolov8åŠ è½½çš„ç›¸å¯¹è·¯å¾„

```
from ultralytics import YOLO
model path = 'weights/yolov8n.pt'
```

```
streamlit run main.py
```



## è®¾ç½®ç½®ä¿¡åº¦

```python
from ultralytics import YOLO
import streamlit as st

# åŠ è½½æ¨¡å‹
model_path = 'weights/yolov8n.pt'
model = YOLO(model_path)

# æ·»åŠ ä¸€ä¸ªæ»‘å—ç”¨äºé€‰æ‹©ç½®ä¿¡åº¦é˜ˆå€¼
confidence = float(st.slider(
    "Select Model Confidence",
    25, 100, 40  # æœ€å°å€¼ã€æœ€å¤§å€¼ã€é»˜è®¤å€¼
)) / 100  # è½¬æ¢ä¸º 0~1 çš„æµ®ç‚¹æ•°
```

![image-20250627015041167](assets/image-20250627015041167.png)





```python
from ultralytics import YOLO
import streamlit as st
from PIL import Image
import numpy as np

# é¡µé¢é…ç½®
st.set_page_config(page_title="YOLOv8 å›¾åƒç›®æ ‡æ£€æµ‹", layout="wide")
st.title("YOLOv8 ç›®æ ‡æ£€æµ‹åº”ç”¨")

# åŠ è½½æ¨¡å‹
model_path = 'weights/yolov8n.pt'

try:
    model = YOLO(model_path)
    st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as ex:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {model_path}")
    st.error(f"é”™è¯¯è¯¦æƒ…: {str(ex)}")
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

with st.sidebar:
    st.header("Image/Video Config")
    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹", type=["jpg", "jpeg", "png"])

    # æ·»åŠ ä¸€ä¸ªæ»‘å—ç”¨äºé€‰æ‹©ç½®ä¿¡åº¦é˜ˆå€¼
    confidence = float(st.slider(
        "é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦é˜ˆå€¼",
        25, 100, 40  # æœ€å°å€¼ã€æœ€å¤§å€¼ã€é»˜è®¤å€¼
    )) / 100  # è½¬æ¢ä¸º 0~1 çš„æµ®ç‚¹æ•°

if uploaded_file is not None:
    # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸º PIL å›¾åƒ
    uploaded_image = Image.open(uploaded_file).convert("RGB")
    uploaded_image_np = np.array(uploaded_image)

    col1, col2 = st.columns(2)

    with col1:
        st.image(uploaded_image, caption='åŸå§‹å›¾åƒ', use_column_width=True)

    if st.sidebar.button('æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡'):
        # æ‰§è¡Œé¢„æµ‹
        results = model.predict(uploaded_image_np, conf=confidence)
        boxes = results[0].boxes
        res_plotted = results[0].plot()[:, :, ::-1]  # BGR -> RGB

        with col2:
            st.image(res_plotted, caption='æ£€æµ‹ç»“æœå›¾åƒ', use_column_width=True)

        try:
            with st.expander("æ£€æµ‹ç»“æœè¯¦ç»†ä¿¡æ¯"):
                for i, box in enumerate(boxes):
                    st.write(f"å¯¹è±¡ {i+1}: {box.xywh}")
        except Exception as ex:
            st.write("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼")
else:
    st.info("è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ä»¥å¼€å§‹æ£€æµ‹ã€‚")
```

![image-20250627022639867](assets/image-20250627022639867.png)







```python
from ultralytics import YOLO
import streamlit as st
from PIL import Image
import numpy as np

# é¡µé¢é…ç½®
st.set_page_config(page_title="YOLOv8 å›¾åƒç›®æ ‡æ£€æµ‹", layout="wide")
st.title("YOLOv8 ç›®æ ‡æ£€æµ‹åº”ç”¨")

# åŠ è½½æ¨¡å‹
model_path = 'weights/yolov8n.pt'

try:
    model = YOLO(model_path)
    st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as ex:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {model_path}")
    st.error(f"é”™è¯¯è¯¦æƒ…: {str(ex)}")
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

with st.sidebar:
    st.header("Image/Video Config")
    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹", type=["jpg", "jpeg", "png"])

    source_vid = st.sidebar.selectbox(
        "Choose a video...",
        ["videos/video_1.mp4"]
     )

# æ·»åŠ ä¸€ä¸ªæ»‘å—ç”¨äºé€‰æ‹©ç½®ä¿¡åº¦é˜ˆå€¼
confidence = float(st.slider(
    "é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦é˜ˆå€¼",
    25, 100, 40  # æœ€å°å€¼ã€æœ€å¤§å€¼ã€é»˜è®¤å€¼
)) / 100  # è½¬æ¢ä¸º 0~1 çš„æµ®ç‚¹æ•°


if uploaded_file is not None:
    # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸º PIL å›¾åƒ
    uploaded_image = Image.open(uploaded_file).convert("RGB")
    uploaded_image_np = np.array(uploaded_image)

    col1, col2 = st.columns(2)

    with col1:
        st.image(uploaded_image, caption='åŸå§‹å›¾åƒ', use_column_width=True)

    if st.sidebar.button('æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡'):
        # æ‰§è¡Œé¢„æµ‹
        results = model.predict(uploaded_image_np, conf=confidence)
        boxes = results[0].boxes
        res_plotted = results[0].plot()[:, :, ::-1]  # BGR -> RGB

        with col2:
            st.image(res_plotted, caption='æ£€æµ‹ç»“æœå›¾åƒ', use_column_width=True)

        try:
            with st.expander("æ£€æµ‹ç»“æœè¯¦ç»†ä¿¡æ¯"):
                for i, box in enumerate(boxes):
                    st.write(f"å¯¹è±¡ {i+1}: {box.xywh}")
        except Exception as ex:
            st.write("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼")
else:
    st.info("è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ä»¥å¼€å§‹æ£€æµ‹ã€‚")
```

![image-20250627023233919](assets/image-20250627023233919.png)











```python
from ultralytics import YOLO
import streamlit as st
from PIL import Image
import numpy as np
import os

# é¡µé¢é…ç½®
st.set_page_config(page_title="YOLOv8 å›¾åƒ/è§†é¢‘ç›®æ ‡æ£€æµ‹", layout="wide")
st.title("YOLOv8 ç›®æ ‡æ£€æµ‹åº”ç”¨")

# åŠ è½½æ¨¡å‹
model_path = 'weights/yolov8n.pt'

try:
    model = YOLO(model_path)
    st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as ex:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {model_path}")
    st.error(f"é”™è¯¯è¯¦æƒ…: {str(ex)}")
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.header("å›¾åƒ/è§†é¢‘é…ç½®")

    # å›¾åƒä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹", type=["jpg", "jpeg", "png"])

    # è§†é¢‘é€‰æ‹©
    st.subheader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
    video_files = [f for f in os.listdir("videos") if f.endswith((".mp4", ".avi", ".mov"))]
    source_vid = st.selectbox("é€‰æ‹©è§†é¢‘æ–‡ä»¶", options=video_files, key="video_selector")

# æ·»åŠ ç½®ä¿¡åº¦æ»‘å—
confidence = float(st.slider(
    "é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦é˜ˆå€¼",
    25, 100, 40
)) / 100

# å¤„ç†å›¾åƒä¸Šä¼ 
if uploaded_file is not None:
    uploaded_image = Image.open(uploaded_file).convert("RGB")
    uploaded_image_np = np.array(uploaded_image)

    col1, col2 = st.columns(2)

    with col1:
        st.image(uploaded_image, caption='åŸå§‹å›¾åƒ', use_column_width=True)

    if st.sidebar.button('æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡'):
        results = model.predict(uploaded_image_np, conf=confidence)
        boxes = results[0].boxes
        res_plotted = results[0].plot()[:, :, ::-1]  # BGR -> RGB

        with col2:
            st.image(res_plotted, caption='æ£€æµ‹ç»“æœå›¾åƒ', use_column_width=True)

        try:
            with st.expander("æ£€æµ‹ç»“æœè¯¦ç»†ä¿¡æ¯"):
                for i, box in enumerate(boxes):
                    st.write(f"å¯¹è±¡ {i + 1}: {box.xywh}")
        except Exception as ex:
            st.write("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼")

# å¤„ç†è§†é¢‘é€‰æ‹©
elif source_vid:
    video_path = os.path.join("videos", source_vid)
    st.info(f"æ­£åœ¨æ’­æ”¾è§†é¢‘: {source_vid}")

    # æ˜¾ç¤ºè§†é¢‘
    with open(video_path, 'rb') as video_file:
        video_bytes = video_file.read()
    if video_bytes:
        st.video(video_bytes)

    # å¯æ‰©å±•ï¼šè§†é¢‘æ£€æµ‹æŒ‰é’®
    if st.button("å¼€å§‹è§†é¢‘ç›®æ ‡æ£€æµ‹"):
        st.warning("æ­¤åŠŸèƒ½å°šæœªå®ç°ã€‚ä½ å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ è§†é¢‘å¸§å¤„ç†é€»è¾‘ã€‚")

else:
    st.info("è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡æˆ–ä»ä¾§è¾¹æ é€‰æ‹©ä¸€ä¸ªè§†é¢‘ä»¥å¼€å§‹æ£€æµ‹ã€‚")
```

![image-20250627023651685](assets/image-20250627023651685.png)















```python
from ultralytics import YOLO
import streamlit as st
from PIL import Image
import numpy as np
import os
import cv2

# é¡µé¢é…ç½®
st.set_page_config(page_title="YOLOv8 è§†é¢‘ç›®æ ‡æ£€æµ‹", layout="wide")
st.title("YOLOv8 è§†é¢‘ç›®æ ‡æ£€æµ‹åº”ç”¨")

# åŠ è½½æ¨¡å‹
model_path = 'weights/yolov8n.pt'
try:
    model = YOLO(model_path)
    st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as ex:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {model_path}")
    st.error(f"é”™è¯¯è¯¦æƒ…: {str(ex)}")
    st.stop()

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.header("å›¾åƒ/è§†é¢‘é…ç½®")

    # å›¾åƒä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹", type=["jpg", "jpeg", "png"])

    # è§†é¢‘é€‰æ‹©å’ŒæŒ‰é’®
    st.subheader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
    video_files = [f for f in os.listdir("videos") if f.endswith((".mp4", ".avi", ".mov"))]
    source_vid = st.selectbox("é€‰æ‹©è§†é¢‘æ–‡ä»¶", options=video_files, key="video_selector")
    but = st.button('å¼€å§‹è§†é¢‘ç›®æ ‡æ£€æµ‹')

if but:
    if source_vid:
        video_path = os.path.join("videos", source_vid)
        cap = cv2.VideoCapture(video_path)

        frame_placeholder = st.empty()
        stop_button = st.button(label="åœæ­¢æ£€æµ‹")

        while cap.isOpened() and not stop_button:
            ret, frame = cap.read()
            if not ret:
                break

            results = model.predict(frame, conf=0.4)
            res_plotted = results[0].plot()

            # æ˜¾ç¤ºå¤„ç†åçš„å¸§
            frame_placeholder.image(res_plotted, channels="BGR", use_column_width=True)

        cap.release()
    else:
        st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")

# æ·»åŠ ç½®ä¿¡åº¦æ»‘å—ï¼ˆä»…ç”¨äºå›¾åƒï¼‰
if uploaded_file is not None:
    confidence = float(st.slider(
        "é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦é˜ˆå€¼",
        25, 100, 40
    )) / 100

    uploaded_image = Image.open(uploaded_file).convert("RGB")
    uploaded_image_np = np.array(uploaded_image)

    col1, col2 = st.columns(2)

    with col1:
        st.image(uploaded_image, caption='åŸå§‹å›¾åƒ', use_column_width=True)

    if st.sidebar.button('æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡'):
        results = model.predict(uploaded_image_np, conf=confidence)
        boxes = results[0].boxes
        res_plotted = results[0].plot()[:, :, ::-1]  # BGR -> RGB

        with col2:
            st.image(res_plotted, caption='æ£€æµ‹ç»“æœå›¾åƒ', use_column_width=True)

        try:
            with st.expander("æ£€æµ‹ç»“æœè¯¦ç»†ä¿¡æ¯"):
                for i, box in enumerate(boxes):
                    st.write(f"å¯¹è±¡ {i + 1}: {box.xywh}")
        except Exception as ex:
            st.write("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼")
else:
    st.info("è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡æˆ–ä»ä¾§è¾¹æ é€‰æ‹©ä¸€ä¸ªè§†é¢‘ä»¥å¼€å§‹æ£€æµ‹ã€‚")
```

![image-20250627024039800](assets/image-20250627024039800.png)











# åŠ è½½æœ¬åœ°å›¾ & YOLOV8



```python
model = YOLO("weights/yolov8n-cls.pt")
results = model.predict("images/test.jpg", imgsz=600, show=True, save=True)
print('æµ‹è¯•ç»“æœâ€”â€”ã€‹', results)
```

![image-20250627174830803](assets/image-20250627174830803.png)

![image-20250627180239139](assets/image-20250627180239139.png)



```python
model = YOLO("weights/yolov8n.pt")
results = model("images/test1.jpg", imgsz=600, show=True, save=True)
print(f'ç›®æ ‡æ£€æµ‹é¢„æµ‹ç»“æœ --> ', results)
```

![image-20250627175712214](assets/image-20250627175712214.png)

![image-20250627180304789](assets/image-20250627180304789.png)





```python
model_path = "weights/yolov8n.pt"
vid_path = "videos/video2.mp4"
model = YOLO(model_path)
results = model.track(vid_path, conf=0.3, iou=0.5, persist=True, show=True, save=True)
```

![image-20250627175632683](assets/image-20250627175632683.png)













# é‡æ„å›¾åƒç›®æ ‡æ£€æµ‹

```python
from pathlib import Path
from PIL import Image
import streamlit as st
import settings
import helper

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="Object Detection using YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Object Detection using YOLOv8")
st.sidebar.header("ML Model Config")

# æ¨¡å‹ä»»åŠ¡é€‰æ‹©ï¼ˆè¿™é‡Œåªä¿ç•™äº†Detectionï¼‰
model_type = st.sidebar.radio("Select Task", ['Detection'])

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# åŠ è½½æ¨¡å‹è·¯å¾„
if model_type == 'Detection':
    model_path = Path(settings.DETECTION_MODEL)

# åŠ è½½æ¨¡å‹
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"Unable to load model. Check the specified path: {model_path}")
    st.error(ex)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# å›¾åƒ/è§†é¢‘æºé…ç½®
st.sidebar.header("Image/Video Config")
source_radio = st.sidebar.radio("Select Source", settings.SOURCES_LIST)

# é»˜è®¤å›¾åƒè·¯å¾„
default_image_path = str(settings.DEFAULT_IMAGE)

# åˆå§‹åŒ– uploaded_image å˜é‡
uploaded_image = None

# å›¾åƒä¸Šä¼ é€»è¾‘
if source_radio == settings.IMAGE:
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if source_img is not None:
        try:
            uploaded_image = Image.open(source_img)
        except Exception as ex:
            st.error("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.error(ex)
    else:
        # æ˜¾ç¤ºé»˜è®¤å›¾ç‰‡
        uploaded_image = Image.open(default_image_path)
else:
    st.error("ç›®å‰ä»…æ”¯æŒå›¾åƒè¾“å…¥ã€‚")

# å±•ç¤ºå›¾åƒåˆ—
col1, col2 = st.columns(2)

with col1:
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Input Image", use_column_width=True)
    else:
        st.warning("æœªåŠ è½½å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒã€‚")

# æ¨ç†ä¸ç»“æœå±•ç¤º
with col2:
    if st.sidebar.button('Detect Objects'):
        if uploaded_image is not None:
            with st.spinner("æ­£åœ¨æ¨ç†..."):
                res = model.predict(uploaded_image, conf=confidence)
                boxes = res[0].boxes
                res_plotted = res[0].plot()[:, :, ::-1]  # è½¬æ¢ä¸º RGB æ˜¾ç¤º

                # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
                st.image(res_plotted, caption='Detected Image', use_column_width=True)

                # æ˜¾ç¤ºæ£€æµ‹æ¡†æ•°æ®
                try:
                    with st.expander("Detection Results"):
                        for idx, box in enumerate(boxes):
                            st.write(f"å¯¹è±¡ {idx+1}: {box.data}")
                except Exception as ex:
                    st.write("æœªèƒ½æå–æ£€æµ‹æ¡†ä¿¡æ¯ã€‚")
                    st.exception(ex)
        else:
            st.warning("è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼")
```

![image-20250627181515144](assets/image-20250627181515144.png)









```python
from pathlib import Path
from PIL import Image
import streamlit as st
import settings
import helper
import os
import cv2

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="Object Detection using YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Object Detection using YOLOv8")

# æ¨¡å‹ä»»åŠ¡é€‰æ‹©ï¼ˆè¿™é‡Œåªä¿ç•™äº†Detectionï¼‰
model_type = st.sidebar.radio("Select Task", ['Detection'])

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# åŠ è½½æ¨¡å‹è·¯å¾„
if model_type == 'Detection':
    model_path = Path(settings.DETECTION_MODEL)

# åŠ è½½æ¨¡å‹
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"Unable to load model. Check the specified path: {model_path}")
    st.error(ex)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# å›¾åƒ/è§†é¢‘æºé…ç½®
source_radio = st.sidebar.radio("Select Source", ["Image", "Video"])

# é»˜è®¤å›¾åƒè·¯å¾„
default_image_path = str(settings.DEFAULT_IMAGE)

# åˆå§‹åŒ– uploaded_image å˜é‡
uploaded_image = None

# å›¾åƒä¸Šä¼ é€»è¾‘
if source_radio == "Image":
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if source_img is not None:
        try:
            uploaded_image = Image.open(source_img)
        except Exception as ex:
            st.error("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.error(ex)
    else:
        # æ˜¾ç¤ºé»˜è®¤å›¾ç‰‡
        uploaded_image = Image.open(default_image_path)

# è§†é¢‘é€‰æ‹©å’ŒæŒ‰é’®
elif source_radio == "Video":
    st.subheader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
    video_files = [f for f in os.listdir("videos") if f.endswith((".mp4", ".avi", ".mov"))]
    source_vid = st.selectbox("é€‰æ‹©è§†é¢‘æ–‡ä»¶", options=video_files, key="video_selector")
    but = st.button('Detect Video Objects', key="detect_video")

    if but:
        if source_vid:
            video_path = os.path.join("videos", source_vid)
            cap = cv2.VideoCapture(video_path)

            frame_placeholder = st.empty()
            stop_button = st.button(label="åœæ­¢æ£€æµ‹")

            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    break

                results = model.predict(frame, conf=confidence)
                res_plotted = results[0].plot()

                # æ˜¾ç¤ºå¤„ç†åçš„å¸§
                frame_placeholder.image(res_plotted, channels="BGR", use_column_width=True)

            cap.release()
        else:
            st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
else:
    st.error("Please select a valid source type!")

# å±•ç¤ºå›¾åƒåˆ—
col1, col2 = st.columns(2)

with col1:
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Input Image", use_column_width=True)
    else:
        st.warning("æœªåŠ è½½å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒã€‚")

# æ¨ç†ä¸ç»“æœå±•ç¤º
with col2:
    but = st.sidebar.button('Detect Objects', key="detect_image")
    if but and uploaded_image is not None:
        with st.spinner("æ­£åœ¨æ¨ç†..."):
            res = model.predict(uploaded_image, conf=confidence)
            boxes = res[0].boxes
            res_plotted = res[0].plot()[:, :, ::-1]  # è½¬æ¢ä¸º RGB æ˜¾ç¤º

            # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
            st.image(res_plotted, caption='Detected Image', use_column_width=True)

            # æ˜¾ç¤ºæ£€æµ‹æ¡†æ•°æ®
            try:
                with st.expander("Detection Results"):
                    for idx, box in enumerate(boxes):
                        st.write(f"å¯¹è±¡ {idx+1}: {box.data}")
            except Exception as ex:
                st.write("æœªèƒ½æå–æ£€æµ‹æ¡†ä¿¡æ¯ã€‚")
                st.exception(ex)
    elif but:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼")
```

![image-20250627183246071](assets/image-20250627183246071.png)















```python
from pathlib import Path
import sys

# Get the absolute path of the current file
FILE = Path(__file__).resolve()
# Get the parent directory of the current file
ROOT = FILE.parent
if ROOT not in sys.path:
    sys.path.append(str(ROOT))
ROOT = ROOT.relative_to(Path.cwd())

# Sources
IMAGE = 'Image'
VIDEO = 'Video'
SOURCES_LIST = [IMAGE, VIDEO]
# Images config
IMAGES_DIR = ROOT / 'images'
DEFAULT_IMAGE = IMAGES_DIR / 'test1.jpg'

# Videos config
VIDEO_DIR = ROOT / 'videos'
VIDEOS_DIST = {
    'video_1': VIDEO_DIR / 'video_1.mp4',
    'video_2': VIDEO_DIR / 'video_2.mp4',
    'video_3': VIDEO_DIR / 'video_3.mp4',
    'video_4': VIDEO_DIR / 'video_4.mp4', }
# ML Model config
MODEL_DIR = ROOT / 'weights'
DETECTION_MODEL = MODEL_DIR / 'yolov8n.pt'

# YOLOv8 Segmentation model path
SEGMENTATION_MODEL = "weights/yolov8n-seg.pt"
```

```python
from pathlib import Path
from PIL import Image
import streamlit as st
import settings
import helper
import os
import cv2

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="Object Detection & Segmentation using YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Object Detection & Segmentation using YOLOv8")

# æ£€æŸ¥ settings.py ä¸­æ˜¯å¦æœ‰å¿…éœ€çš„å±æ€§
for attr in ['DETECTION_MODEL', 'SEGMENTATION_MODEL', 'DEFAULT_IMAGE']:
    if not hasattr(settings, attr):
        st.error(f"Settings file missing required attribute: {attr}")
        st.stop()

# æ¨¡å‹ä»»åŠ¡é€‰æ‹©
model_type = st.sidebar.radio("Select Task", ['Detection', 'Segmentation'])

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# åŠ è½½æ¨¡å‹è·¯å¾„
if model_type == 'Detection':
    model_path = Path(settings.DETECTION_MODEL)
elif model_type == 'Segmentation':
    model_path = Path(settings.SEGMENTATION_MODEL)

# éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
if not model_path.exists():
    st.error(f"Model file does not exist at the specified path: {model_path}")
    st.stop()

# åŠ è½½æ¨¡å‹
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"Unable to load model. Check the specified path: {model_path}")
    st.error(ex)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# å›¾åƒ/è§†é¢‘æºé…ç½®
source_radio = st.sidebar.radio("Select Source", ["Image", "Video"])

# é»˜è®¤å›¾åƒè·¯å¾„
default_image_path = str(settings.DEFAULT_IMAGE)

# åˆå§‹åŒ– uploaded_image å˜é‡
uploaded_image = None

# å›¾åƒä¸Šä¼ é€»è¾‘
if source_radio == "Image":
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if source_img is not None:
        try:
            uploaded_image = Image.open(source_img)
        except Exception as ex:
            st.error("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.error(ex)
    else:
        # æ˜¾ç¤ºé»˜è®¤å›¾ç‰‡
        uploaded_image = Image.open(default_image_path)

# è§†é¢‘é€‰æ‹©å’ŒæŒ‰é’®
elif source_radio == "Video":
    st.subheader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
    video_files = [f for f in os.listdir("videos") if f.endswith((".mp4", ".avi", ".mov"))]
    source_vid = st.selectbox("é€‰æ‹©è§†é¢‘æ–‡ä»¶", options=video_files, key="video_selector")
    but = st.button('Detect Video Objects', key="detect_video")

    if but:
        if source_vid:
            video_path = os.path.join("videos", source_vid)
            cap = cv2.VideoCapture(video_path)

            frame_placeholder = st.empty()
            stop_button = st.button(label="åœæ­¢æ£€æµ‹")

            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    break

                results = model.predict(frame, conf=confidence)
                res_plotted = results[0].plot()  # plot ä¼šè‡ªåŠ¨å¤„ç† detection å’Œ segmentation

                # æ˜¾ç¤ºå¤„ç†åçš„å¸§
                frame_placeholder.image(res_plotted, channels="BGR", use_column_width=True)

            cap.release()
        else:
            st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
else:
    st.error("Please select a valid source type!")

# å±•ç¤ºå›¾åƒåˆ—
col1, col2 = st.columns(2)

with col1:
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Input Image", use_column_width=True)
    else:
        st.warning("æœªåŠ è½½å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒã€‚")

# æ¨ç†ä¸ç»“æœå±•ç¤º
with col2:
    but = st.sidebar.button('Detect Objects', key="detect_image")
    if but and uploaded_image is not None:
        with st.spinner("æ­£åœ¨æ¨ç†..."):
            res = model.predict(uploaded_image, conf=confidence)
            boxes = res[0].boxes
            res_plotted = res[0].plot()[:, :, ::-1]  # è½¬æ¢ä¸º RGB æ˜¾ç¤º

            # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
            st.image(res_plotted, caption='Detected Image', use_column_width=True)

            # æ˜¾ç¤ºæ£€æµ‹æ¡†æ•°æ®
            try:
                with st.expander("Detection Results"):
                    for idx, box in enumerate(boxes):
                        st.write(f"å¯¹è±¡ {idx+1}: {box.data}")
            except Exception as ex:
                st.write("æœªèƒ½æå–æ£€æµ‹æ¡†ä¿¡æ¯ã€‚")
                st.exception(ex)
    elif but:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼")
```

![image-20250627185022088](assets/image-20250627185022088.png)

![image-20250627185033565](assets/image-20250627185033565.png)









```
import cv2
import streamlit as st
from ultralytics import YOLO


def load_model(model_path):
    """
    åŠ è½½ YOLO æ¨¡å‹
    """
    model = YOLO(model_path)
    return model


def _display_detected_frames(conf, model, st_frame, image):
    """
    ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œå¹¶åœ¨ Streamlit ä¸­æ˜¾ç¤ºç»“æœå¸§
    """
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
    results = model.predict(image, conf=conf)

    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    res_plotted = results[0].plot()

    # åœ¨ Streamlit ä¸­æ˜¾ç¤ºå›¾åƒ
    st_frame.image(res_plotted,
                   caption='Detected Video',
                   channels="BGR",
                   use_column_width=True)


def play_online_video(conf, model):
    """
    æ’­æ”¾åœ¨çº¿è§†é¢‘å¹¶å®æ—¶æ£€æµ‹
    """
    source_video_url = st.sidebar.text_input("Online Video URL")

    if st.sidebar.button('Detect Objects', key="detect_online_video"):
        try:
            if source_video_url:
                # æ˜¾ç¤ºè§†é¢‘æ’­æ”¾å™¨ï¼ˆä»…ç”¨äºé¢„è§ˆï¼‰
                st.video(source_video_url)

                # æ‰“å¼€è§†é¢‘æµ
                vid_cap = cv2.VideoCapture(source_video_url)

                st_frame = st.empty()
                stop_button = st.button("Stop Detection")

                while vid_cap.isOpened() and not stop_button:
                    success, image = vid_cap.read()
                    if success:
                        _display_detected_frames(conf, model, st_frame, image)
                    else:
                        vid_cap.release()
                        break
            else:
                st.warning("è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘é“¾æ¥ã€‚")
        except Exception as e:
            st.sidebar.error("Error loading video: " + str(e))
```

```
from pathlib import Path
import sys

# Get the absolute path of the current file
FILE = Path(__file__).resolve()
# Get the parent directory of the current file
ROOT = FILE.parent
if ROOT not in sys.path:
    sys.path.append(str(ROOT))
ROOT = ROOT.relative_to(Path.cwd())

# Sources
IMAGE = 'Image'
VIDEO = 'Video'
ONLINE_VIDEO = 'OnlineVideo'

SOURCES_LIST = [IMAGE, VIDEO, ONLINE_VIDEO]
# Images config
IMAGES_DIR = ROOT / 'images'
DEFAULT_IMAGE = IMAGES_DIR / 'test1.jpg'

# Videos config
VIDEO_DIR = ROOT / 'videos'
VIDEOS_DIST = {
    'video_1': VIDEO_DIR / 'video_1.mp4',
    'video_2': VIDEO_DIR / 'video_2.mp4',
    'video_3': VIDEO_DIR / 'video_3.mp4',
    'video_4': VIDEO_DIR / 'video_4.mp4', }
# ML Model config
MODEL_DIR = ROOT / 'weights'
DETECTION_MODEL = MODEL_DIR / 'yolov8n.pt'

# YOLOv8 Segmentation model path
SEGMENTATION_MODEL = "weights/yolov8n-seg.pt"
```

```
from pathlib import Path
from PIL import Image
import streamlit as st
import settings
import helper
import os
import cv2

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="Object Detection & Segmentation using YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Object Detection & Segmentation using YOLOv8")

# æ£€æŸ¥ settings.py ä¸­æ˜¯å¦æœ‰å¿…éœ€çš„å±æ€§
for attr in ['DETECTION_MODEL', 'SEGMENTATION_MODEL', 'DEFAULT_IMAGE']:
    if not hasattr(settings, attr):
        st.error(f"Settings file missing required attribute: {attr}")
        st.stop()

# æ¨¡å‹ä»»åŠ¡é€‰æ‹©
model_type = st.sidebar.radio("Select Task", ['Detection', 'Segmentation'])

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# åŠ è½½æ¨¡å‹è·¯å¾„
if model_type == 'Detection':
    model_path = Path(settings.DETECTION_MODEL)
elif model_type == 'Segmentation':
    model_path = Path(settings.SEGMENTATION_MODEL)

# éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
if not model_path.exists():
    st.error(f"Model file does not exist at the specified path: {model_path}")
    st.stop()

# åŠ è½½æ¨¡å‹
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"Unable to load model. Check the specified path: {model_path}")
    st.error(ex)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# å›¾åƒ/è§†é¢‘æºé…ç½®
source_radio = st.sidebar.radio("Select Source", settings.SOURCES_LIST)

# é»˜è®¤å›¾åƒè·¯å¾„
default_image_path = str(settings.DEFAULT_IMAGE)

# åˆå§‹åŒ– uploaded_image å˜é‡
uploaded_image = None

# å›¾åƒä¸Šä¼ é€»è¾‘
if source_radio == "Image":
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if source_img is not None:
        try:
            uploaded_image = Image.open(source_img)
        except Exception as ex:
            st.error("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.error(ex)
    else:
        # æ˜¾ç¤ºé»˜è®¤å›¾ç‰‡
        uploaded_image = Image.open(default_image_path)

# è§†é¢‘é€‰æ‹©å’ŒæŒ‰é’®
elif source_radio == "Video":
    st.subheader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
    video_files = [f for f in os.listdir("videos") if f.endswith((".mp4", ".avi", ".mov"))]
    source_vid = st.selectbox("é€‰æ‹©è§†é¢‘æ–‡ä»¶", options=video_files, key="video_selector")
    but = st.button('Detect Video Objects', key="detect_video")

    if but:
        if source_vid:
            video_path = os.path.join("videos", source_vid)
            cap = cv2.VideoCapture(video_path)

            frame_placeholder = st.empty()
            stop_button = st.button(label="åœæ­¢æ£€æµ‹")

            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    break

                results = model.predict(frame, conf=confidence)
                res_plotted = results[0].plot()  # plot ä¼šè‡ªåŠ¨å¤„ç† detection å’Œ segmentation

                # æ˜¾ç¤ºå¤„ç†åçš„å¸§
                frame_placeholder.image(res_plotted, channels="BGR", use_column_width=True)

            cap.release()
        else:
            st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
elif source_radio == settings.ONLINE_VIDEO:
    helper.play_online_video(confidence, model)
else:
    st.error("Please select a valid source type!")

# å±•ç¤ºå›¾åƒåˆ—
col1, col2 = st.columns(2)

with col1:
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Input Image", use_column_width=True)
    else:
        st.warning("æœªåŠ è½½å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒã€‚")

# æ¨ç†ä¸ç»“æœå±•ç¤º
with col2:
    but = st.sidebar.button('Detect Objects', key="detect_image")
    if but and uploaded_image is not None:
        with st.spinner("æ­£åœ¨æ¨ç†..."):
            res = model.predict(uploaded_image, conf=confidence)
            boxes = res[0].boxes
            res_plotted = res[0].plot()[:, :, ::-1]  # è½¬æ¢ä¸º RGB æ˜¾ç¤º

            # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
            st.image(res_plotted, caption='Detected Image', use_column_width=True)

            # æ˜¾ç¤ºæ£€æµ‹æ¡†æ•°æ®
            try:
                with st.expander("Detection Results"):
                    for idx, box in enumerate(boxes):
                        st.write(f"å¯¹è±¡ {idx+1}: {box.data}")
            except Exception as ex:
                st.write("æœªèƒ½æå–æ£€æµ‹æ¡†ä¿¡æ¯ã€‚")
                st.exception(ex)
    elif but:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼")
```

![image-20250627185805697](assets/image-20250627185805697.png)



























```python
from pathlib import Path
from PIL import Image
import streamlit as st
import settings
import helper_all as helper

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="Object Detection & Segmentation using YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ‡é¢˜
st.title("Object Detection & Segmentation using YOLOv8")

# æ£€æŸ¥ settings.py ä¸­æ˜¯å¦æœ‰å¿…éœ€çš„å±æ€§
for attr in ['DETECTION_MODEL', 'SEGMENTATION_MODEL', 'DEFAULT_IMAGE']:
    if not hasattr(settings, attr):
        st.error(f"Settings file missing required attribute: {attr}")
        st.stop()

# æ¨¡å‹ä»»åŠ¡é€‰æ‹©
model_type = st.sidebar.radio("Select Task", ['Detection', 'Segmentation'])

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100

# åŠ è½½æ¨¡å‹è·¯å¾„
if model_type == 'Detection':
    model_path = Path(settings.DETECTION_MODEL)
elif model_type == 'Segmentation':
    model_path = Path(settings.SEGMENTATION_MODEL)

# éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
if not model_path.exists():
    st.error(f"Model file does not exist at the specified path: {model_path}")
    st.stop()

# åŠ è½½æ¨¡å‹
try:
    model = helper.load_model(model_path)
except Exception as ex:
    st.error(f"Unable to load model. Check the specified path: {model_path}")
    st.error(ex)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# å›¾åƒ/è§†é¢‘æºé…ç½®
source_radio = st.sidebar.radio("Select Source", settings.SOURCES_LIST)

# é»˜è®¤å›¾åƒè·¯å¾„
default_image_path = str(settings.DEFAULT_IMAGE)

# åˆå§‹åŒ– uploaded_image å˜é‡
uploaded_image = None

# å›¾åƒä¸Šä¼ é€»è¾‘
if source_radio == settings.IMAGE:
    source_img = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if source_img is not None:
        try:
            uploaded_image = Image.open(source_img)
        except Exception as ex:
            st.error("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.error(ex)
    else:
        # æ˜¾ç¤ºé»˜è®¤å›¾ç‰‡
        uploaded_image = Image.open(default_image_path)

# è§†é¢‘é€‰æ‹©å’ŒæŒ‰é’®
elif source_radio == settings.VIDEO:
    helper.play_stored_video(confidence, model)
elif source_radio == settings.ONLINE_VIDEO:
    helper.play_online_video(confidence, model)
else:
    st.error("Please select a valid source type!")

# å±•ç¤ºå›¾åƒåˆ—
col1, col2 = st.columns(2)

with col1:
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Input Image", use_column_width=True)
    else:
        st.warning("æœªåŠ è½½å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒã€‚")

# æ¨ç†ä¸ç»“æœå±•ç¤º
with col2:
    but = st.sidebar.button('Detect Objects', key="detect_image")
    if but and uploaded_image is not None:
        with st.spinner("æ­£åœ¨æ¨ç†..."):
            res = model.predict(uploaded_image, conf=confidence)
            boxes = res[0].boxes
            res_plotted = res[0].plot()[:, :, ::-1]  # è½¬æ¢ä¸º RGB æ˜¾ç¤º

            # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
            st.image(res_plotted, caption='Detected Image', use_column_width=True)

            # æ˜¾ç¤ºæ£€æµ‹æ¡†æ•°æ®
            try:
                with st.expander("Detection Results"):
                    for idx, box in enumerate(boxes):
                        st.write(f"å¯¹è±¡ {idx+1}: {box.data}")
            except Exception as ex:
                st.write("æœªèƒ½æå–æ£€æµ‹æ¡†ä¿¡æ¯ã€‚")
                st.exception(ex)
    elif but:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼")
```

```python
from ultralytics import YOLO
import streamlit as st
import cv2
import settings
import os


def load_model(model_path):
    """
    åŠ è½½ YOLOv8 æ¨¡å‹
    """
    model = YOLO(model_path)
    return model


def display_tracker_options():
    """
    æ˜¾ç¤ºæ˜¯å¦å¯ç”¨ç›®æ ‡è·Ÿè¸ªé€‰é¡¹
    """
    display_tracker = st.radio("Display Tracker", ('Yes', 'No'))
    is_display_tracker = display_tracker == 'Yes'

    tracker_type = None
    if is_display_tracker:
        tracker_type = st.radio("Select Tracker", ("bytetrack.yaml", "botsort.yaml"))

    return is_display_tracker, tracker_type


def _display_detected_frames(conf, model, st_frame, image, is_display_tracking=None, tracker=None):
    """
    åœ¨ Streamlit ä¸­æ˜¾ç¤ºæ£€æµ‹æˆ–è·Ÿè¸ªç»“æœå¸§
    """
    image = cv2.resize(image, (720, int(720 * (9 / 16))))  # è°ƒæ•´å›¾åƒå°ºå¯¸ç”¨äºæ˜¾ç¤º

    if is_display_tracking:
        results = model.track(image, conf=conf, persist=True, tracker=tracker)
    else:
        results = model.predict(image, conf=conf)

    res_plotted = results[0].plot()

    st_frame.image(res_plotted,
                   caption='Detected Video',
                   channels="BGR",
                   use_column_width=True)


def play_stored_video(conf, model):
    """
    æ’­æ”¾æœ¬åœ°å­˜å‚¨çš„è§†é¢‘å¹¶è¿›è¡Œæ£€æµ‹æˆ–è·Ÿè¸ª
    """
    source_vid = st.sidebar.selectbox("Choose a video...", settings.VIDEOS_DICT.keys())

    is_display_tracker, tracker = display_tracker_options()

    video_path = settings.VIDEOS_DICT.get(source_vid)
    if not video_path or not os.path.exists(video_path):
        st.warning("Selected video file does not exist.")
        return

    try:
        # é¢„è§ˆè§†é¢‘
        with open(video_path, 'rb') as video_file:
            video_bytes = video_file.read()
        if video_bytes:
            st.video(video_bytes)

        if st.sidebar.button('Detect Video Objects', key="detect_stored_video"):
            vid_cap = cv2.VideoCapture(video_path)
            st_frame = st.empty()
            stop_button = st.button("Stop Detection")

            while vid_cap.isOpened() and not stop_button:
                success, image = vid_cap.read()
                if success:
                    _display_detected_frames(conf, model, st_frame, image, is_display_tracker, tracker)
                else:
                    vid_cap.release()
                    break

    except Exception as e:
        st.sidebar.error(f"Error loading video: {str(e)}")


def play_online_video(conf, model):
    """
    æ’­æ”¾åœ¨çº¿è§†é¢‘å¹¶è¿›è¡Œæ£€æµ‹æˆ–è·Ÿè¸ª
    """
    source_video_url = st.sidebar.text_input("Online Video URL")

    if st.sidebar.button('Detect Online Video', key="detect_online_video"):
        try:
            if source_video_url:
                st.video(source_video_url)
                vid_cap = cv2.VideoCapture(source_video_url)
                st_frame = st.empty()
                stop_button = st.button("Stop Detection")

                is_display_tracker, tracker = display_tracker_options()

                while vid_cap.isOpened() and not stop_button:
                    success, image = vid_cap.read()
                    if success:
                        _display_detected_frames(conf, model, st_frame, image, is_display_tracker, tracker)
                    else:
                        vid_cap.release()
                        break
            else:
                st.warning("è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘é“¾æ¥ã€‚")
        except Exception as e:
            st.sidebar.error(f"Error loading online video: {str(e)}")
```

```python
from pathlib import Path
import sys

# Get the absolute path of the current file
FILE = Path(__file__).resolve()
# Get the parent directory of the current file
ROOT = FILE.parent
if ROOT not in sys.path:
    sys.path.append(str(ROOT))
ROOT = ROOT.relative_to(Path.cwd())

# Sources
IMAGE = 'Image'
VIDEO = 'Video'
ONLINE_VIDEO = 'OnlineVideo'

SOURCES_LIST = [IMAGE, VIDEO, ONLINE_VIDEO]
# Images config
IMAGES_DIR = ROOT / 'images'
DEFAULT_IMAGE = IMAGES_DIR / 'test1.jpg'

# Videos config
VIDEO_DIR = ROOT / 'videos'
VIDEOS_DIST = {
    'video_1': VIDEO_DIR / 'video1.mp4',
    'video_2': VIDEO_DIR / 'video2.mp4',
    'video_3': VIDEO_DIR / 'video3.mp4',
    'video_4': VIDEO_DIR / 'video4.mp4', }
# ML Model config
MODEL_DIR = ROOT / 'weights'
DETECTION_MODEL = MODEL_DIR / 'yolov8n.pt'

# YOLOv8 Segmentation model path
SEGMENTATION_MODEL = "weights/yolov8n-seg.pt"

VIDEOS_DICT = {
    "Sample Video 1": "videos/video1.mp4",
    "Sample Video 2": "videos/video2.mp4"
}
```

![image-20250627191648768](assets/image-20250627191648768.png)